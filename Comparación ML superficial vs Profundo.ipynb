{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4341d802",
   "metadata": {},
   "source": [
    "Comparación Modelo Superficial vs Modelo Profundo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cb7103",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, RocCurveDisplay, PrecisionRecallDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy import stats\n",
    "\n",
    "# --- Ajusta la ruta a tu csv ---\n",
    "CSV_PATH = r\"D:\\MAXITEL\\Escritorio\\ginger\\MAESTRIA\\INTELIGENCIA ARTIFICIAL\\proyecto-ml-telecom\\Supervisado\\ocrdataset.csv\"\n",
    "\n",
    "# 1) Cargar\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"Shape inicial:\", df.shape)\n",
    "\n",
    "# 2) Verifica existencia de la columna target\n",
    "target = \"Signal Quality\"\n",
    "if target not in df.columns:\n",
    "    raise ValueError(f\"No se encontró la columna target '{target}' en el CSV. Columnas disponibles: {df.columns.tolist()}\")\n",
    "\n",
    "# 3) Filtrar clases raras\n",
    "vc = df[target].value_counts()\n",
    "keep_classes = vc[vc >= 2].index\n",
    "df = df[df[target].isin(keep_classes)].reset_index(drop=True)\n",
    "\n",
    "# 4) X, y y codificación\n",
    "X = df.drop(columns=[target])\n",
    "\n",
    "# Convertir automáticamente todas las variables categóricas (strings) a numéricas\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "y_raw = df[target].values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_raw)\n",
    "\n",
    "print(\"Shape final de X:\", X.shape)\n",
    "print(\"Clases finales:\", le.classes_)\n",
    "\n",
    "# 5) Split estratificado\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 6) Escalado: fit en train, transform en test (evita data leakage)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 7) Entrenamiento: Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300, max_depth=15, class_weight=\"balanced\",\n",
    "    random_state=42, n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "rf_pred = rf.predict(X_test_scaled)\n",
    "rf_proba = rf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"=== Random Forest ===\")\n",
    "print(classification_report(y_test, rf_pred, target_names=le.classes_))\n",
    "\n",
    "# 8) Entrenamiento: MLP\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64), activation=\"relu\",\n",
    "    solver=\"adam\", learning_rate_init=0.001, max_iter=500,\n",
    "    random_state=42\n",
    ")\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "mlp_pred = mlp.predict(X_test_scaled)\n",
    "mlp_proba = mlp.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"=== Red Neuronal (MLP) ===\")\n",
    "print(classification_report(y_test, mlp_pred, target_names=le.classes_))\n",
    "\n",
    "# 9) Matrices de confusión\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "sns.heatmap(confusion_matrix(y_test, rf_pred), annot=True, fmt=\"d\", ax=ax[0])\n",
    "ax[0].set_title(\"Random Forest\")\n",
    "sns.heatmap(confusion_matrix(y_test, mlp_pred), annot=True, fmt=\"d\", ax=ax[1])\n",
    "ax[1].set_title(\"MLP\")\n",
    "plt.show()\n",
    "\n",
    "# 10) ROC y Precision-Recall\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "RocCurveDisplay.from_predictions(y_test, rf_proba, name=\"Random Forest\", ax=ax[0])\n",
    "RocCurveDisplay.from_predictions(y_test, mlp_proba, name=\"MLP\", ax=ax[0])\n",
    "ax[0].set_title(\"ROC\")\n",
    "PrecisionRecallDisplay.from_predictions(y_test, rf_proba, name=\"Random Forest\", ax=ax[1])\n",
    "PrecisionRecallDisplay.from_predictions(y_test, mlp_proba, name=\"MLP\", ax=ax[1])\n",
    "ax[1].set_title(\"Precision-Recall\")\n",
    "plt.show()\n",
    "\n",
    "# 11) Validación cruzada y prueba estadística — usar pipeline para evitar data leakage en CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rf_pipe = make_pipeline(StandardScaler(), RandomForestClassifier(\n",
    "    n_estimators=300, max_depth=15, class_weight=\"balanced\", random_state=42, n_jobs=-1\n",
    "))\n",
    "mlp_pipe = make_pipeline(StandardScaler(), MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64), max_iter=500, random_state=42\n",
    "))\n",
    "\n",
    "rf_scores = cross_val_score(rf_pipe, X, y, cv=cv, scoring=\"f1_macro\")\n",
    "mlp_scores = cross_val_score(mlp_pipe, X, y, cv=cv, scoring=\"f1_macro\")\n",
    "\n",
    "t_stat, p_val = stats.ttest_rel(mlp_scores, rf_scores)\n",
    "\n",
    "print(\"=== Comparación estadística ===\")\n",
    "print(\"RF F1 promedio:\", np.mean(rf_scores), \"std:\", np.std(rf_scores))\n",
    "print(\"MLP F1 promedio:\", np.mean(mlp_scores), \"std:\", np.std(mlp_scores))\n",
    "print(\"t-stat:\", t_stat, \"p-value:\", p_val)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
